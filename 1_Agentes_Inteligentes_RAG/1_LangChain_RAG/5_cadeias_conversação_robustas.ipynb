{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:44:32.046587Z",
     "start_time": "2026-01-14T15:44:32.036420Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install langchain langchain-google-genai langchain-community chromadb tiktoken google-genai",
   "id": "e3ed16aaa2b41468",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T15:45:30.909013Z",
     "start_time": "2026-01-14T15:44:32.279586Z"
    }
   },
   "source": [
    "from langchain_classic.chains import ConversationalRetrievalChain\n",
    "from langchain_classic.memory import ConversationBufferWindowMemory\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_classic.schema import Document\n",
    "import google.genai as genai\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Data preparation",
   "id": "4f4ab128fcb7680"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:45:31.807063Z",
     "start_time": "2026-01-14T15:45:31.799189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documentos_exemplo = [\n",
    "    \"\"\"Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
    "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
    "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\"\"\",\n",
    "\n",
    "    \"\"\"Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
    "    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\n",
    "    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\"\"\",\n",
    "\n",
    "    \"\"\"Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
    "    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\n",
    "    processamento de linguagem natural e reconhecimento de voz.\"\"\",\n",
    "\n",
    "    \"\"\"RAG (Retrieval-Augmented Generation) √© uma t√©cnica que combina recupera√ß√£o de informa√ß√µes\n",
    "    com gera√ß√£o de texto. Permite que modelos de linguagem acessem conhecimento externo\n",
    "    para gerar respostas mais precisas e atualizadas.\"\"\",\n",
    "\n",
    "    \"\"\"LangChain √© um framework para desenvolvimento de aplica√ß√µes com modelos de linguagem.\n",
    "    Facilita a cria√ß√£o de cadeias complexas, gerenciamento de mem√≥ria e integra√ß√£o\n",
    "    com diferentes fontes de dados.\"\"\",\n",
    "\n",
    "    \"\"\"Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google,\n",
    "    capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de\n",
    "    racioc√≠nio e compreens√£o contextual.\"\"\"\n",
    "]\n",
    "\n",
    "# Convers√£o para objetos Document\n",
    "docs = [Document(page_content=doc) for doc in documentos_exemplo]"
   ],
   "id": "280cbe0d0fa46b1e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. VectorStore creation with genai embeddings",
   "id": "b2dfd2b1d38b7de0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:45:44.231713Z",
     "start_time": "2026-01-14T15:45:31.838477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./vectorstore_chroma_genai\"\n",
    ")\n",
    "\n",
    "print(f\"N¬∫ de docs indexados: {vectorstore._collection.count()}\")"
   ],
   "id": "13463073e7d14b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de docs indexados: 6\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Memory management",
   "id": "9ccc16a6d515c83a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:59:11.291530Z",
     "start_time": "2026-01-14T19:59:11.269518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")"
   ],
   "id": "a446dff30b24d20a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. ConversationalRetrievalChain with Gemini",
   "id": "1003c1516c28e71c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:59:16.737934Z",
     "start_time": "2026-01-14T19:59:15.507359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.7,\n",
    "    convert_system_message_to_human=True\n",
    ")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "1978ab26b66542d5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Testing the conversation",
   "id": "644b91e1dd097fa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:02:48.602916Z",
     "start_time": "2026-01-14T20:02:41.127903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_question(question):\n",
    "    \"\"\"Question making function for conversational chain\"\"\"\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        result = qa_chain({\"question\": question})\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"\\nUtilized documents: {len(result['source_documents'])}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "result1 = do_question(\"O que √© Intelig√™ncia Artificial?\")"
   ],
   "id": "e5132a2dc63d6d8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: O que √© Intelig√™ncia Artificial?\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da Intelig√™ncia Artificial (IA) que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Seus algoritmos identificam padr√µes em dados e fazem previs√µes.\n",
      "Follow Up Input: O que √© Intelig√™ncia Artificial?\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
      "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
      "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "\n",
      "Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
      "    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\n",
      "    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "\n",
      "Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
      "    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\n",
      "    processamento de linguagem natural e reconhecimento de voz.\n",
      "Human: O que √© Intelig√™ncia Artificial?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "\n",
      "Utilized documents: 3\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:02:54.085956Z",
     "start_time": "2026-01-14T20:02:50.494601Z"
    }
   },
   "cell_type": "code",
   "source": "result1 = do_question(\"O que √© Machine Learning?\") # Keep previous questions memory",
   "id": "9ad32ffb658c8971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: O que √© Machine Learning?\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da Intelig√™ncia Artificial (IA) que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Seus algoritmos identificam padr√µes em dados e fazem previs√µes.\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Follow Up Input: O que √© Machine Learning?\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
      "    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\n",
      "    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "\n",
      "Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
      "    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\n",
      "    processamento de linguagem natural e reconhecimento de voz.\n",
      "\n",
      "Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
      "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
      "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "\n",
      "Utilized documents: 3\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:08:22.352558Z",
     "start_time": "2026-01-14T20:08:16.157456Z"
    }
   },
   "cell_type": "code",
   "source": "result3 = do_question(\"E o que √© Google Gemini como voce mencionou?\")",
   "id": "6bb5f374c0aa9679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: E o que √© Google Gemini como voce mencionou?\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da Intelig√™ncia Artificial (IA) que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Seus algoritmos identificam padr√µes em dados e fazem previs√µes.\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "Follow Up Input: E o que √© Google Gemini como voce mencionou?\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google,\n",
      "    capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de\n",
      "    racioc√≠nio e compreens√£o contextual.\n",
      "\n",
      "RAG (Retrieval-Augmented Generation) √© uma t√©cnica que combina recupera√ß√£o de informa√ß√µes\n",
      "    com gera√ß√£o de texto. Permite que modelos de linguagem acessem conhecimento externo\n",
      "    para gerar respostas mais precisas e atualizadas.\n",
      "\n",
      "Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
      "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
      "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Google Gemini?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google, capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de racioc√≠nio e compreens√£o contextual.\n",
      "\n",
      "Utilized documents: 3\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 6. Security guardrails",
   "id": "9ee563be3103caef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:21:09.012074Z",
     "start_time": "2026-01-14T20:21:08.950241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "class SecurityGuardrails:\n",
    "    def __init__(self):\n",
    "        self.forbidden_words = [\n",
    "            'senha', 'password', 'cpf', 'rg', 'cart√£o de cr√©dito',\n",
    "            'dados pessoais', 'informa√ß√£o confidencial', 'api key',\n",
    "            'chave de api', 'token de acesso'\n",
    "        ]\n",
    "\n",
    "        self.pii_standards = [\n",
    "            r'\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}',        # Padr√£o CPF (999.999.999-99)\n",
    "            r'\\d{4}\\s?\\d{4}\\s?\\d{4}\\s?\\d{4}',    # Padr√£o cart√£o de cr√©dito (16 d√≠gitos)\n",
    "            r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',  # Padr√£o e-mail\n",
    "            r'AIza[0-9A-Za-z\\-_]{35}'            # Padr√£o Google API Key\n",
    "        ]\n",
    "\n",
    "    def validate_question(self, query):\n",
    "        \"\"\"Verify if the question contains inappropriate content\"\"\"\n",
    "        normalized_question = query.lower()\n",
    "\n",
    "        for forbidden_word in self.forbidden_words:\n",
    "            if forbidden_word in normalized_question:\n",
    "                return False, f\"Question has inadequate term: {forbidden_word}\"\n",
    "\n",
    "        for standard in self.pii_standards:\n",
    "            if re.search(standard, query):\n",
    "                return False, \"Question has personal information\"\n",
    "\n",
    "        return True, \"Approved question\"\n",
    "\n",
    "    def validate_response(self, response):\n",
    "        \"\"\"Verify if the response is appropriate and safe to return to the user.\"\"\"\n",
    "        normalized_response = response.lower()\n",
    "\n",
    "        relevant_terms = ['ia', 'intelig√™ncia artificial', 'machine learning',\n",
    "                         'deep learning', 'rag', 'langchain', 'gemini', 'google']\n",
    "\n",
    "        contains_relevant_terms = any(term in normalized_response for term in relevant_terms)\n",
    "\n",
    "        if not contains_relevant_terms and len(response) > 50:\n",
    "            return False, \"Out of scope response\"\n",
    "\n",
    "        for standard in self.pii_standards:\n",
    "            if re.search(standard, response):\n",
    "                return False, \"Response has sensible information\"\n",
    "\n",
    "        return True, \"Approved response\"\n",
    "\n",
    "guardrails = SecurityGuardrails()\n",
    "print(\"Security Guardrails ready!\")\n"
   ],
   "id": "ad490ac458537348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security Guardrails ready!\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:26:19.253721Z",
     "start_time": "2026-01-14T20:26:10.267158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def secure_question(question):\n",
    "    \"\"\"Question making function for conversational chain\"\"\"\n",
    "    q_approved, q_message = guardrails.validate_question(question)\n",
    "\n",
    "    if not q_approved:\n",
    "        print(f\"Question not approved: {q_message}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        result = qa_chain({\"question\": question})\n",
    "        r_approved, r_message = guardrails.validate_response(result['answer'])\n",
    "        if not r_approved:\n",
    "            print(f\"Response not approved: {r_message}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"{q_message}\")\n",
    "        print(f\"{r_message}\")\n",
    "        print(f\"Response: {result['answer']}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Secure question test\")\n",
    "secure_question(\"Explain Deep Learning\")"
   ],
   "id": "54c2c956ad77389e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secure question test\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da Intelig√™ncia Artificial (IA) que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Seus algoritmos identificam padr√µes em dados e fazem previs√µes.\n",
      "Human: O que √© Intelig√™ncia Artificial?\n",
      "Assistant: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Machine Learning?\n",
      "Assistant: Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "Human: E o que √© Google Gemini como voce mencionou?\n",
      "Assistant: Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google, capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de racioc√≠nio e compreens√£o contextual.\n",
      "Follow Up Input: Explain Deep Learning\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
      "    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\n",
      "    processamento de linguagem natural e reconhecimento de voz.\n",
      "\n",
      "Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
      "    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\n",
      "    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.\n",
      "\n",
      "Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
      "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
      "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.\n",
      "Human: O que √© Deep Learning?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Approved question\n",
      "Approved response\n",
      "Response: Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem, processamento de linguagem natural e reconhecimento de voz.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Explain Deep Learning',\n",
       " 'chat_history': [HumanMessage(content='O que √© Intelig√™ncia Artificial?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       "  HumanMessage(content='O que √© Machine Learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine Learning √© uma sub√°rea da Intelig√™ncia Artificial (IA) que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Seus algoritmos identificam padr√µes em dados e fazem previs√µes.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       "  HumanMessage(content='O que √© Intelig√™ncia Artificial?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       "  HumanMessage(content='O que √© Machine Learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados. Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       "  HumanMessage(content='E o que √© Google Gemini como voce mencionou?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google, capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de racioc√≠nio e compreens√£o contextual.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])],\n",
       " 'answer': 'Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem, processamento de linguagem natural e reconhecimento de voz.',\n",
       " 'source_documents': [Document(metadata={}, page_content='Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\\n    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\\n    processamento de linguagem natural e reconhecimento de voz.'),\n",
       "  Document(metadata={}, page_content='Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\\n    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\\n    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes.'),\n",
       "  Document(metadata={}, page_content='Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\\n    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\\n    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes.')]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:27:09.652151Z",
     "start_time": "2026-01-14T20:27:09.639248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Insecure question test\")\n",
    "secure_question(\"Qual √© a sua chave de API?\")"
   ],
   "id": "f83e42fdd8706b4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insecure question test\n",
      "Question not approved: Question has inadequate term: chave de api\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Improved reranking",
   "id": "24368986a110ee2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T20:53:15.677595Z",
     "start_time": "2026-01-14T20:53:10.475424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class RerankGemini:\n",
    "    \"\"\"Reranking class using Gemini Embeddings\"\"\"\n",
    "    def __init__(self, embeddings_model):\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.name = \"Re-ranking with Gemini Embeddings\"\n",
    "\n",
    "    def rerank(self, query, documents, top_k=3):\n",
    "        try:\n",
    "            # Creating vector from question\n",
    "            query_embedding = self.embeddings_model.embed_query(query)\n",
    "\n",
    "            # Generating embeddings from documents\n",
    "            doc_texts = [doc.page_content if hasattr(doc, \"page_content\") else str(doc) for doc in documents]\n",
    "            doc_embeddings = self.embeddings_model.embed_documents(doc_texts)\n",
    "\n",
    "            # Calculate similarities\n",
    "            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "            # Create document score list\n",
    "            scored_docs = list(zip(similarities, documents)) # Combine score and docs in tuples\n",
    "\n",
    "            return [doc for _, doc in scored_docs[:top_k]]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return self._simple_rerank(query, documents, top_k)\n",
    "\n",
    "    def _simple_rerank(self, query, documents, top_k):\n",
    "        query_words = set(query.lower().split())\n",
    "\n",
    "        scored_docs = []\n",
    "        for doc in documents:\n",
    "            doc_text = doc.page_content if hasattr(doc, \"page_content\") else str(doc)\n",
    "            doc_words = set(doc_text.lower().split())\n",
    "            score = len(query_words.intersection(doc_words)) / len(query_words) if query_words else 0.0\n",
    "            scored_docs.append((score, doc))\n",
    "\n",
    "        scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [doc for _, doc in scored_docs[:top_k]]\n",
    "\n",
    "reranker = RerankGemini(embeddings_model=embeddings)\n",
    "print(\"Reranker ready!\")"
   ],
   "id": "eaad5fa40cfe1b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker ready!\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:55:07.653834Z",
     "start_time": "2026-01-14T23:55:04.062559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reranked_search(query, k=5, top_k=3):\n",
    "\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "\n",
    "    try:\n",
    "        initial_docs = vectorstore.similarity_search(query, k=k)\n",
    "        print(f\"Initial documents found: {len(initial_docs)}\")\n",
    "\n",
    "        reranked_docs = reranker.rerank(query, initial_docs, top_k=top_k)\n",
    "        print(f\"Reranked documents found: {len(reranked_docs)}\")\n",
    "\n",
    "        print(f\"\\nReranked documents:\")\n",
    "        for i, doc in enumerate(reranked_docs, start=1):\n",
    "            content = doc.page_content if hasattr(doc, \"page_content\") else str(doc)\n",
    "            print(f\"{i}. {content[:100]}...\")\n",
    "\n",
    "        return reranked_docs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "docs_result = reranked_search(\"machine learning algoritmos gemini\")"
   ],
   "id": "8c212f485033921c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: machine learning algoritmos gemini\n",
      "Initial documents found: 5\n",
      "Reranked documents found: 3\n",
      "\n",
      "Reranked documents:\n",
      "1. Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google,\n",
      "    capaz de processar t...\n",
      "2. Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
      "    automatica...\n",
      "3. Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
      "    com m√∫ltipl...\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Conclusion",
   "id": "b11198d5209ca58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook, we explored the core concepts of **Robust Conversational Chains** using **Google Gemini**:\n",
    "\n",
    "‚úÖ **ConversationalRetrievalChain**: We implemented a chain that maintains conversational context with Gemini\n",
    "‚úÖ **Memory Management**: We configured memory to preserve interaction history\n",
    "‚úÖ **Security Guardrails**: We created specific filters to protect sensitive information\n",
    "‚úÖ **Re-ranking with Gemini**: We implemented re-ranking using Gemini embeddings\n",
    "\n",
    "### üöÄ Advantages of Google Gemini\n",
    "\n",
    "- **Multimodal**: Ability to process text, images, and code\n",
    "- **Cost-effective**: Competitive pricing compared to other models\n",
    "- **Google Integration**: Seamless integration with other Google services\n",
    "- **Performance**: Excellent response quality and reasoning\n",
    "\n",
    "### üîß Next Steps\n",
    "\n",
    "1. **Experiment** with different Gemini models (such as `gemini-pro-vision` for images)\n",
    "2. **Optimize** costs through token analysis\n",
    "3. **Implement** response caching to reduce API calls\n",
    "4. **Integrate** with Google Cloud for production environments\n",
    "5. **Explore** Gemini's multimodal capabilities\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- [Google AI Studio](https://makersuite.google.com/)\n",
    "- [Gemini API Documentation](https://ai.google.dev/docs)\n",
    "- [LangChain + Gemini](https://python.langchain.com/docs/integrations/llms/google_ai)\n",
    "- [Gemini Pricing](https://ai.google.dev/pricing)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** üéâ You have completed the practical notebook on Robust Conversational Chains with Google Gemini!"
   ],
   "id": "a15cb2bb85eb9a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Understanding Query Reformulation\n",
    "In robust conversational chains, query reformulation consists of converting a history-dependent question into a standalone and self-contained query. This process involves analyzing the conversation history to identify relevant references and context, then reconstructing the question so it contains all the necessary information for more accurate data retrieval. Consequently, the reformulated question no longer relies on previous elements and can be understood in isolation by information retrieval systems.\n",
    "\n",
    "#### Reasoning Behind the Process\n",
    "This technique leverages the ability of Large Language Models (LLMs) to understand contextual nuances and resolve ambiguities. By transforming a dependent query into an autonomous one, the system avoids common pitfalls such as context loss or misinterpretations caused by ambiguous pronouns and references. This reformulation enhances response coherence and relevance by enabling:\n",
    "\n",
    "* The full integration of information from the interaction history.\n",
    "\n",
    "* The systematic resolution of ambiguities.\n",
    "\n",
    "* The creation of queries that maximize the probability of retrieving documents or data that precisely meet the user's intent.\n",
    "\n",
    "#### Exemplifying the Approach\n",
    "Imagine a scenario where a user starts a dialogue asking about the reimbursement process. If they follow up with \"how long does it take?\", query reformulation transforms this second question into something like: \"How long does the reimbursement process take?\". Thus, even if the original input was fragmented, the system constructs a complete and precise query.\n",
    "\n",
    "This technique is typically implemented as an intermediate step in RAG (Retrieval-Augmented Generation) systems, utilizing LLMs to analyze the dialogue and generate the reformulated version of the query. Implementation may vary based on dialogue complexity and application requirements, but the goal remains the same: to increase fidelity and effectiveness in information retrieval."
   ],
   "id": "3ebed6ae22a4aa7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this lesson, we explored the construction of a robust chatbot that maintains context, utilizes security guardrails, and applies re-ranking to improve document retrieval.\n",
    "\n",
    "Now it's your turn to put the concepts presented in class into practice, if you haven't already. To do so:\n",
    "\n",
    "* **Develop a conversational chain** that manages history and reformulates queries.\n",
    "* **Configure a `ConversationBufferWindowMemory`** to store the last 5 interactions.\n",
    "* **Create a VectorStore** using **Google Gemini Embeddings** to index the documents.\n",
    "* **Set up the LLM** with the **Google Gemini** model, defining parameters such as the API key and temperature.\n",
    "* **Implement security guardrails** to filter unwanted inputs and responses.\n",
    "* **Develop a function** to send queries to the chatbot and display the responses including the history.\n",
    "* **Implement a re-ranking mechanism** to reorder documents based on relevance."
   ],
   "id": "d6620602f15f36a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this lesson, we learned:\n",
    "\n",
    "* How to create robust conversational chains using **LangChain**.\n",
    "* How to implement conversational memory management with **`ConversationBufferWindowMemory`**.\n",
    "* How to combine document retrieval with LLMs to improve dialogue coherence.\n",
    "* How to use the **re-ranking** technique to order documents based on contextual relevance.\n",
    "* How to configure **security guardrails** to filter content and protect personal information.\n",
    "* How to configure **VectorStores** with **ChromaDB** for efficient document indexing and search.\n",
    "* How to use **Google Generative AI embeddings** to improve retrieval precision.\n",
    "* How to split text into **chunks** to facilitate data processing and analysis."
   ],
   "id": "3634eab96ddc3990"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f80b519bb4d0951d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
