{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T22:16:13.090390Z",
     "start_time": "2026-01-15T22:16:13.076703Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install ragas",
   "id": "76e084eed36fbeab",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-15T22:16:13.675063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_classic.chains import ConversationalRetrievalChain\n",
    "from langchain_classic.memory import ConversationBufferWindowMemory\n",
    "from langchain_classic.vectorstores import Chroma\n",
    "from langchain_classic.schema import Document\n",
    "from langchain_classic.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics.collections import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import google.genai as genai\n",
    "from sympy.physics.units import temperature\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Preparing test data",
   "id": "af874ddb32896afa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:54:55.484150Z",
     "start_time": "2026-01-15T21:54:55.475761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "knowledge_docs = [\n",
    "    \"\"\"Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra\n",
    "    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana.\n",
    "    Isso inclui aprendizado, racioc√≠nio, percep√ß√£o e tomada de decis√µes. A IA pode ser classificada\n",
    "    em IA fraca (espec√≠fica para tarefas) e IA forte (intelig√™ncia geral).\"\"\",\n",
    "\n",
    "    \"\"\"Machine Learning √© uma sub√°rea da IA que permite que computadores aprendam e melhorem\n",
    "    automaticamente atrav√©s da experi√™ncia, sem serem explicitamente programados.\n",
    "    Os algoritmos de ML identificam padr√µes em dados e fazem previs√µes. Existem tr√™s tipos principais:\n",
    "    aprendizado supervisionado, n√£o supervisionado e por refor√ßo.\"\"\",\n",
    "\n",
    "    \"\"\"Deep Learning √© uma t√©cnica de machine learning baseada em redes neurais artificiais\n",
    "    com m√∫ltiplas camadas. √â especialmente eficaz para tarefas como reconhecimento de imagem,\n",
    "    processamento de linguagem natural e reconhecimento de voz. As redes neurais profundas\n",
    "    podem ter centenas de camadas e milh√µes de par√¢metros.\"\"\",\n",
    "\n",
    "    \"\"\"RAG (Retrieval-Augmented Generation) √© uma t√©cnica que combina recupera√ß√£o de informa√ß√µes\n",
    "    com gera√ß√£o de texto. Permite que modelos de linguagem acessem conhecimento externo\n",
    "    para gerar respostas mais precisas e atualizadas. O processo envolve buscar documentos\n",
    "    relevantes e usar essas informa√ß√µes para gerar a resposta final.\"\"\",\n",
    "\n",
    "    \"\"\"Google Gemini √© um modelo de linguagem multimodal desenvolvido pelo Google,\n",
    "    capaz de processar texto, imagens e c√≥digo. Oferece capacidades avan√ßadas de\n",
    "    racioc√≠nio e compreens√£o contextual. O Gemini vem em diferentes vers√µes:\n",
    "    Nano, Pro e Ultra, cada uma otimizada para diferentes casos de uso.\"\"\",\n",
    "\n",
    "    \"\"\"LangChain √© um framework para desenvolvimento de aplica√ß√µes com modelos de linguagem.\n",
    "    Facilita a cria√ß√£o de cadeias complexas, gerenciamento de mem√≥ria e integra√ß√£o\n",
    "    com diferentes fontes de dados. Oferece componentes modulares para construir\n",
    "    aplica√ß√µes robustas de IA conversacional.\"\"\"\n",
    "]\n",
    "\n",
    "# Convers√£o para objetos Document\n",
    "docs = [Document(page_content=doc) for doc in knowledge_docs]\n",
    "\n",
    "print(f\"{len(docs)} knowledge documents created.\")"
   ],
   "id": "b9aaa4ef0fe5376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 knowledge documents created.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:54:55.514392Z",
     "start_time": "2026-01-15T21:54:55.504654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria√ß√£o de dataset de teste para avalia√ß√£o RAGAS\n",
    "test_data = {\n",
    "    'question': [\n",
    "        \"O que √© Intelig√™ncia Artificial?\",\n",
    "        \"Como funciona o Machine Learning?\",\n",
    "        \"Quais s√£o as aplica√ß√µes do Deep Learning?\",\n",
    "        \"O que √© RAG e como funciona?\",\n",
    "        \"Quais s√£o as caracter√≠sticas do Google Gemini?\"\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "        \"Intelig√™ncia Artificial √© um campo da ci√™ncia da computa√ß√£o focado na cria√ß√£o de sistemas que realizam tarefas que requerem intelig√™ncia humana, incluindo aprendizado, racioc√≠nio e tomada de decis√µes.\",\n",
    "        \"Machine Learning permite que computadores aprendam automaticamente atrav√©s da experi√™ncia, identificando padr√µes em dados para fazer previs√µes, sem programa√ß√£o expl√≠cita.\",\n",
    "        \"Deep Learning √© eficaz para reconhecimento de imagem, processamento de linguagem natural e reconhecimento de voz, usando redes neurais com m√∫ltiplas camadas.\",\n",
    "        \"RAG combina recupera√ß√£o de informa√ß√µes com gera√ß√£o de texto, permitindo que modelos acessem conhecimento externo para respostas mais precisas.\",\n",
    "        \"Google Gemini √© um modelo multimodal que processa texto, imagens e c√≥digo, oferecendo capacidades avan√ßadas de racioc√≠nio em vers√µes Nano, Pro e Ultra.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Dataset created!\")\n",
    "print(f\"üìä {len(test_data['question'])} test questions created.\")"
   ],
   "id": "c24c53f4adb6419c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset created!\n",
      "üìä 5 test questions created.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. RAG system creation",
   "id": "74e45b69836f70fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:55:05.017988Z",
     "start_time": "2026-01-15T21:54:55.568822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=\"./chroma_db_evaluation\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3, convert_system_message_to_human=True)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3, return_messages=True, output_key=\"answer\")\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\":3}),\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "id": "e345fa33e5ecaea1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_16640\\2210280011.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3, return_messages=True, output_key=\"answer\")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Understanding the Cascade Effect\n",
    "In **RAG (Retrieval-Augmented Generation)** systems, every component‚Äîfrom retrieval to response generation‚Äîcan be thought of as part of a chain where an error in one stage can decisively impact the rest. This phenomenon, known as the **cascade effect**, means that an initial failure, such as retrieving irrelevant or incomplete documents, can lead to incorrect or even confusing responses, compromising the reliability of the entire system.\n",
    "\n",
    "When the input for the language model is poorly grounded, even a robust LLM tends to produce responses that do not align with the expected context. Thus, the system exemplifies the **\"garbage in, garbage out\"** principle, reinforcing the need for a meticulous evaluation of every stage.\n",
    "\n",
    "\n",
    "\n",
    "### Error Propagation: From Retrieval to Generation\n",
    "Imagine a scenario where the retrieval layer fails to fetch essential documents for the user's query. The lack of relevant information results in a fragile context base. When this context is passed to the generation layer, the model may produce a response with low factuality, as it lacks the correct data to validate its textual output.\n",
    "\n",
    "This interdependence makes the evaluation of RAG systems more complex; it is necessary not only to measure the quality of each component in isolation but also how they integrate and contribute to the system's overall performance.\n",
    "\n",
    "### Example of Error Propagation\n",
    "Consider the following illustrative pseudocode:\n",
    "\n",
    "```python\n",
    "# Simulation of a simplified chain in a RAG system\n",
    "\n",
    "# Step 1: Document Retrieval\n",
    "documents = retrieve_documents(query)\n",
    "\n",
    "# Simplified document quality validation\n",
    "if not documents or relevant_documents_count(documents) < 0.5:\n",
    "    log_error('Retrieval failed: insufficient context')\n",
    "    context = 'generic content'\n",
    "else:\n",
    "    context = combine_documents(documents)\n",
    "\n",
    "# Step 2: Response generation based on context\n",
    "response = model_generate_response(query, context)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "In this example, the check during the retrieval stage allows for the identification of a potential failure before the error propagates to the generation stage. Although simplified, it illustrates the impact that a compromised stage can have on the entire processing chain.\n",
    "\n",
    "### Mitigation Strategies\n",
    "To minimize the impact of the cascade effect, it is fundamental to adopt monitoring and validation mechanisms at each stage. Possible strategies include:\n",
    "\n",
    "* **Retrieval Redundancy:** Using multiple sources or search methods to ensure the context is complete, reducing the chance of isolated failures compromising the system.\n",
    "* **Intermediate Validation:** Implementing checkpoints that validate context quality before proceeding to response generation. This can include using automated metrics to detect discrepancies and inconsistencies.\n",
    "* **Feedback and Dynamic Adjustments:** Creating a feedback loop that allows the system to self-evaluate and adjust parameters based on both quantitative metrics and qualitative evaluations from practical testing.\n",
    "\n",
    "\n",
    "\n",
    "These approaches contribute to a more resilient system, capable of detecting and correcting errors before they turn into cascading failures, thus ensuring more accurate and consistent responses for users."
   ],
   "id": "db08e4363c9655f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Collecting data for evaluation",
   "id": "5806b101923f7196"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:58:14.206251Z",
     "start_time": "2026-01-15T21:55:05.064016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rag_collect_data(questions):\n",
    "    \"\"\"Runs the RAG chain on the provided questions and returns the results.\"\"\"\n",
    "\n",
    "    results = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "        \"ground_truth\": [],\n",
    "    }\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"Processing question {i+1}/{len(questions)}...\")\n",
    "        try:\n",
    "            result = rag_chain.invoke({\"question\": question})\n",
    "\n",
    "            contexts = [doc.page_content for doc in result[\"source_documents\"]]\n",
    "\n",
    "            results[\"question\"].append(question)\n",
    "            results[\"answer\"].append(result[\"answer\"])\n",
    "            results[\"contexts\"].append(contexts)\n",
    "            results[\"ground_truth\"].append(test_data[\"ground_truth\"][i]) # it was better pulling it from the input variables\n",
    "\n",
    "            print(f\"Generated answer: {result['answer'][:100]}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Starting data collection for evaluation...\")\n",
    "evaluation_data = run_rag_collect_data(test_data[\"question\"])\n",
    "\n",
    "print(f\"\\nSuccessfully collected {len(evaluation_data['question'])} questions for evaluation.\")"
   ],
   "id": "e6d91a5271ea3cd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for evaluation...\n",
      "Processing question 1/5...\n",
      "Generated answer: Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se concentra na cria√ß√£o de sist\n",
      "Processing question 2/5...\n",
      "Error processing question 2: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 17.827091795s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}\n",
      "Processing question 3/5...\n",
      "Error processing question 3: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 1.97046724s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}\n",
      "Processing question 4/5...\n",
      "Error processing question 4: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 23.328163974s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n",
      "Processing question 5/5...\n",
      "Error processing question 5: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 46.173591157s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n",
      "\n",
      "Successfully collected 1 questions for evaluation.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. RAGAS evaluation",
   "id": "1daf69ac74adb8ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T22:12:23.752096Z",
     "start_time": "2026-01-15T22:12:23.719203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "print(\"Starting RAGAS evaluation...\")\n",
    "ragas_dataset = Dataset.from_dict(evaluation_data)\n",
    "\n",
    "ragas_metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    "]\n",
    "\n",
    "print(\"\\nRAGAS metrics ready:\")\n",
    "for metric in ragas_metrics:\n",
    "    print(f\"-   {metric.name}\")"
   ],
   "id": "8fa1570b3cf7b4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RAGAS evaluation...\n",
      "\n",
      "RAGAS metrics ready:\n",
      "-   faithfulness\n",
      "-   answer_relevancy\n",
      "-   context_precision\n",
      "-   context_recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_16640\\3787533999.py:1: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_16640\\3787533999.py:1: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_16640\\3787533999.py:1: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_16640\\3787533999.py:1: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import (\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T22:16:04.356082Z",
     "start_time": "2026-01-15T22:15:52.713255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nEvaluating RAGAS metrics...\")\n",
    "\n",
    "# config = RunConfig( # para evitar timeout\n",
    "#     timeout=180,      # Aumenta para 3 minutos por requisi√ß√£o\n",
    "#     max_retries=10,   # Tenta de novo se falhar\n",
    "#     max_workers=2,    # Reduz o paralelismo (o padr√£o costuma ser 16)\n",
    "#     max_wait=60       # Espera at√© 60s entre as tentativas\n",
    "# )\n",
    "\n",
    "ragas_results = evaluate(\n",
    "    dataset=ragas_dataset,\n",
    "    metrics=ragas_metrics,\n",
    "    llm=llm,\n",
    "    embeddings=embeddings,\n",
    "    #run_config=config\n",
    ")\n",
    "print(\"\\nRAGAS evaluation results:\")\n",
    "print(f\"Faithfulness: {ragas_results['faithfulness'][0]:.4f}\")\n",
    "print(f\"Answer relevancy: {ragas_results['answer_relevancy'][0]:.4f}\")\n",
    "print(f\"Context precision: {ragas_results['context_precision'][0]:.4f}\")\n",
    "print(f\"Context recall: {ragas_results['context_recall'][0]:.4f}\")\n",
    "\n",
    "simulated_ragas_results = {\n",
    "    \"faithfulness\": 0.85,\n",
    "    \"answer_relevancy\": 0.78,\n",
    "    \"context_precision\": 0.82,\n",
    "    \"context_recall\": 0.75\n",
    "}\n",
    "for metric, value in simulated_ragas_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ],
   "id": "d3c19a95827f6917",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating RAGAS metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/4 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mEvaluating RAGAS metrics...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# config = RunConfig( # para evitar timeout\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m#     timeout=180,      # Aumenta para 3 minutos por requisi√ß√£o\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m#     max_retries=10,   # Tenta de novo se falhar\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m#     max_workers=2,    # Reduz o paralelismo (o padr√£o costuma ser 16)\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m#     max_wait=60       # Espera at√© 60s entre as tentativas\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m ragas_results = \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mragas_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m=\u001B[49m\u001B[43mragas_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#run_config=config\u001B[39;49;00m\n\u001B[32m     16\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mRAGAS evaluation results:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     18\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFaithfulness: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mragas_results[\u001B[33m'\u001B[39m\u001B[33mfaithfulness\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\ragas\\_analytics.py:278\u001B[39m, in \u001B[36mtrack_was_completed.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    275\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001B[32m    277\u001B[39m     track(IsCompleteEvent(event_type=func.\u001B[34m__name__\u001B[39m, is_completed=\u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[32m--> \u001B[39m\u001B[32m278\u001B[39m     result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    279\u001B[39m     track(IsCompleteEvent(event_type=func.\u001B[34m__name__\u001B[39m, is_completed=\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[32m    281\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\ragas\\evaluation.py:484\u001B[39m, in \u001B[36mevaluate\u001B[39m\u001B[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar, return_executor, allow_nest_asyncio)\u001B[39m\n\u001B[32m    480\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    481\u001B[39m     \u001B[38;5;66;03m# Default behavior: use nest_asyncio for backward compatibility (Jupyter notebooks)\u001B[39;00m\n\u001B[32m    482\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mragas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01masync_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m run\n\u001B[32m--> \u001B[39m\u001B[32m484\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_async_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\ragas\\async_utils.py:156\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(async_func, allow_nest_asyncio)\u001B[39m\n\u001B[32m    148\u001B[39m     loop_type = \u001B[38;5;28mtype\u001B[39m(loop).\u001B[34m__name__\u001B[39m\n\u001B[32m    149\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    150\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCannot execute nested async code with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloop_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    151\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33muvloop does not support nested event loop execution. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    152\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPlease use asyncio\u001B[39m\u001B[33m'\u001B[39m\u001B[33ms standard event loop in Jupyter environments, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    153\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mor refactor your code to avoid nested async calls.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    154\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masyncio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoro\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001B[39m, in \u001B[36m_patch_asyncio.<locals>.run\u001B[39m\u001B[34m(main, debug)\u001B[39m\n\u001B[32m     28\u001B[39m task = asyncio.ensure_future(main)\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m task.done():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\nest_asyncio.py:92\u001B[39m, in \u001B[36m_patch_loop.<locals>.run_until_complete\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m     90\u001B[39m     f._log_destroy_pending = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f.done():\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._stopping:\n\u001B[32m     94\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\nest_asyncio.py:115\u001B[39m, in \u001B[36m_patch_loop.<locals>._run_once\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    108\u001B[39m     heappop(scheduled)\n\u001B[32m    110\u001B[39m timeout = (\n\u001B[32m    111\u001B[39m     \u001B[32m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ready \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._stopping\n\u001B[32m    112\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;28mmax\u001B[39m(\n\u001B[32m    113\u001B[39m         scheduled[\u001B[32m0\u001B[39m]._when - \u001B[38;5;28mself\u001B[39m.time(), \u001B[32m0\u001B[39m), \u001B[32m86400\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m scheduled\n\u001B[32m    114\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m event_list = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_selector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    116\u001B[39m \u001B[38;5;28mself\u001B[39m._process_events(event_list)\n\u001B[32m    118\u001B[39m end_time = \u001B[38;5;28mself\u001B[39m.time() + \u001B[38;5;28mself\u001B[39m._clock_resolution\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\selectors.py:323\u001B[39m, in \u001B[36mSelectSelector.select\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    321\u001B[39m ready = []\n\u001B[32m    322\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m323\u001B[39m     r, w, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_readers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_writers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[32m    325\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\selectors.py:314\u001B[39m, in \u001B[36mSelectSelector._select\u001B[39m\u001B[34m(self, r, w, _, timeout)\u001B[39m\n\u001B[32m    313\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_select\u001B[39m(\u001B[38;5;28mself\u001B[39m, r, w, _, timeout=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m314\u001B[39m     r, w, x = \u001B[43mselect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    315\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m r, w + x, []\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Detailed metrics analysis",
   "id": "f8d4fbbd8eab83e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:58:16.847033600Z",
     "start_time": "2026-01-15T18:57:44.083228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_metric(results):\n",
    "    \"\"\" Analyzes the provided results and prints a detailed analysis of the metrics.\"\"\"\n",
    "\n",
    "    # 1. Convert EvaluationResult to dict\n",
    "    if hasattr(results, \"to_dict\"):\n",
    "        results = results.to_dict()\n",
    "    elif hasattr(results, \"_scores_dict\"):\n",
    "        results = results._scores_dict\n",
    "    elif not isinstance(results, dict):\n",
    "        results = dict(results)\n",
    "\n",
    "    # 2. Secure helper to get score as scalar\n",
    "    def get_score(key: str, default: float = 0.0) -> float:\n",
    "        result_value = results.get(key, default)\n",
    "        if isinstance(result_value, (list, tuple)):\n",
    "            return float(result_value[0])\n",
    "        return float(result_value)\n",
    "\n",
    "    print(\"Detailed metric analysis:\")\n",
    "\n",
    "    # 3. Expected metrics\n",
    "    metrics = {\n",
    "        \"faithfulness\": \"faithfulness\",\n",
    "        \"answer_relevancy\": \"answer relevancy\",\n",
    "        \"context_relevancy\": \"context relevancy\",\n",
    "        \"context_precision\": \"context precision\",\n",
    "        \"context_recall\": \"context recall\"\n",
    "    }\n",
    "    valid_scores = []\n",
    "    for key, legible_name in metrics.items():\n",
    "        if key not in results:\n",
    "            continue\n",
    "        score = get_score(key)\n",
    "        valid_scores.append(score)\n",
    "\n",
    "        print(f\"- {legible_name}: {score:.4f}\")\n",
    "\n",
    "        if score >= 0.8:\n",
    "            print(\" Excellent\")\n",
    "        elif score >= 0.6:\n",
    "            print(\" Good\")\n",
    "        else:\n",
    "            print(\" Poor\")\n",
    "\n",
    "    # 4. Overall score\n",
    "    if valid_scores:\n",
    "        overall_score = float(np.mean(valid_scores))\n",
    "        print(f\"\\nOverall score: {overall_score:.4f}\")\n",
    "\n",
    "        if overall_score >= 0.8:\n",
    "            print(\" Excellent\")\n",
    "        elif overall_score >= 0.6:\n",
    "            print(\" Good\")\n",
    "        else:\n",
    "            print(\" Poor\")\n",
    "    else:\n",
    "        print(\"No metrics available\")"
   ],
   "id": "62e6f678ed122347",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T21:58:16.881665300Z",
     "start_time": "2026-01-15T18:59:52.671029Z"
    }
   },
   "cell_type": "code",
   "source": "analyze_metric(ragas_results)",
   "id": "2c5a02e86448027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metric analysis:\n",
      "- faithfulness: nan\n",
      " Poor\n",
      "- answer relevancy: 0.8078\n",
      " Excellent\n",
      "- context precision: nan\n",
      " Poor\n",
      "- context recall: nan\n",
      " Poor\n",
      "\n",
      "Overall score: nan\n",
      " Poor\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this lesson, we saw how to evaluate a **RAG system** using **LangSmith** and **Ragas**, covering everything from initial setup to executing metrics.\n",
    "\n",
    "Now it's your chance to review and practice the concepts from this lesson, if you haven't already. To do so:\n",
    "\n",
    "* **Install and import** the necessary libraries and tools (`LangChain`, `ChromaDB`, `Google Generative AI`, etc.).\n",
    "* **Configure access keys** and import project dependencies, including auxiliary functions.\n",
    "* **Prepare the test data** by creating knowledge documents and a Q&A dataset (questions and reference answers).\n",
    "* **Configure the RAG system**: initialize embeddings, create the vector store, instantiate the LLM, and define the memory and query chain.\n",
    "* **Implement data collection**, iterating through questions to store generated answers, contexts, and reference ground truths.\n",
    "* **Configure and execute the evaluation with Ragas**, using metrics such as **faithfulness**, **relevance**, **precision**, and **recall**, and analyze the final results.\n",
    "\n",
    "\n",
    "In this lesson, we learned:\n",
    "\n",
    "* **The importance of evaluation** in RAG systems and the challenges associated with its complexity.\n",
    "* **Using LangSmith** as an observability platform to track and monitor RAG systems.\n",
    "* **The utilization of the Ragas library** to provide specific metrics focused on faithfulness and relevance.\n",
    "* **The implementation of a complete RAG system** using Google Generative AI Embeddings, ChromaDB, and LangChain.\n",
    "* **The configuration of specific metrics**, such as Faithfulness, Answer Relevance, Context Precision, and Context Recall, for RAG evaluation.\n",
    "* **The development of a test dataset** with questions and answers to demonstrate the metrics.\n",
    "* **Data collection and storage** for evaluation, and the use of logs for monitoring.\n",
    "* **Detailed analysis and interpretation of metrics** to evaluate the overall performance of the RAG system."
   ],
   "id": "5b66437ac61310b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "274add1e685e0939"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
