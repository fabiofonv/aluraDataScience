{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "   ### Understanding the Action Pipeline\n",
    "\n",
    "In a system utilizing **Retrieval-Augmented Generation (RAG)**, the action pipeline goes far beyond simple information retrieval. After data is transformed into embeddings and organized within a **vector store**, this stage defines how the agent processes the retrieved information and decides which action to execute to construct a contextualized response. This approach not only ensures the integration between raw data and elaborated answers but also allows the system to apply specific business rules and logic to refine the final output.\n",
    "\n",
    "\n",
    "\n",
    "### Structure and Operational Flow\n",
    "\n",
    "The action pipeline is composed of several modules acting in sequence. Generally, following the semantic query in the vector store:\n",
    "\n",
    "1.  The agent collects the most relevant snippets based on **semantic similarity**.\n",
    "2.  **Validations and transformations** are applied to ensure the data is coherent with the requested context.\n",
    "3.  The system can then trigger **custom functions** or execute additional checks before forming the final response for the user.\n",
    "\n",
    "An illustrative example in pseudocode:\n",
    "\n",
    "```python\n",
    "# Data Retrieval\n",
    "snippets = vector_store.retrieve(query, k=3)\n",
    "\n",
    "# Snippet processing and verification\n",
    "validated_data = []\n",
    "for snippet in snippets:\n",
    "    if validate_snippet(snippet):\n",
    "        validated_data.append(transform_snippet(snippet))\n",
    "\n",
    "# Response construction\n",
    "response = generator_model.generate_response(context=validated_data, question=query)\n",
    "```\n",
    "\n",
    "   This modular flow allows each stage to be adjusted according to the domain's complexity and the specific needs of the application, increasing the conversational agent's reliability.\n",
    "\n",
    "### Critical Aspects and Key Considerations\n",
    "\n",
    "\n",
    "\n",
    "Among the main advantages of this approach, the following stand out:\n",
    "\n",
    "* **Flexibility:** The ability to intersperse validation, transformation, and verification functions allows the system to adapt to different scenarios and domain-specific rulesâ€”for example, interpreting complex football rules in an explainer agent.\n",
    "* **Response Precision:** By integrating an intermediate layer of actions, the system can filter out irrelevant information and ensure the final response is aligned with both the original data and the defined business logic.\n",
    "\n",
    "\n",
    "\n",
    "On the other hand, it is important to consider that a more complex action pipeline may require greater development and testing efforts, as well as special care regarding the **orchestration** between modules to avoid delays or integration errors.\n",
    "\n",
    "This approach highlights how a well-structured flow, which is not limited solely to data retrieval, can significantly contribute to the quality and relevance of responses generated by a RAG-based conversational agent."
   ],
   "id": "a49204fefb39436c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T01:12:26.080647Z",
     "start_time": "2026-01-27T01:12:09.007532Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_classic.chains import RetrievalQA"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\Documents\\Cursos\\aluraDataScience\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Problem definition",
   "id": "94924863626d3834"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T01:12:36.732405Z",
     "start_time": "2026-01-27T01:12:26.612490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CAMINHO_PDF = \"../data/Regras_do_Jogo_2023_24.pdf\"\n",
    "loader = PyPDFLoader(CAMINHO_PDF)\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs)"
   ],
   "id": "f4d2b73d426b66fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Docs preparation",
   "id": "6082caa3d292db9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T01:12:36.804982Z",
     "start_time": "2026-01-27T01:12:36.752082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "len(chunks)"
   ],
   "id": "ffdf25ae0313d50a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Embeddings and vectorstore",
   "id": "221d8112deebff9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T01:17:59.090815Z",
     "start_time": "2026-01-27T01:12:36.852182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"chroma_regras_futebol\"\n",
    ")"
   ],
   "id": "63fb18d5810b180d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Retriever",
   "id": "b15782871a96671a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T01:17:59.202769Z",
     "start_time": "2026-01-27T01:17:59.194632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ],
   "id": "e624e82a30e9690b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. LLM integration",
   "id": "4d9cfc32d4e35e02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T01:18:00.646545Z",
     "start_time": "2026-01-27T01:17:59.290934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")"
   ],
   "id": "e9e51dcebf028394",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
